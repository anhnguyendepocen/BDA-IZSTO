<!DOCTYPE html>
<html>
<head>
  <title>Bayesian Data Analysis for Medical Data</title>

  <meta charset="utf-8">
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="generator" content="pandoc" />




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">

  <base target="_blank">

  <script type="text/javascript">
    var SLIDE_CONFIG = {
      // Slide settings
      settings: {
                title: 'Bayesian Data Analysis for Medical Data',
                        subtitle: 'Model selection',
                useBuilds: true,
        usePrettify: true,
        enableSlideAreas: true,
        enableTouch: true,
                        favIcon: 'main_files/logo.jpg',
              },

      // Author information
      presenters: [
            {
        name:  'Paola Berchialla' ,
        company: '',
        gplus: '',
        twitter: '',
        www: '',
        github: ''
      },
            ]
    };
  </script>

  <link href="main_files/ioslides-13.5.1/fonts/fonts.css" rel="stylesheet" />
  <link href="main_files/ioslides-13.5.1/theme/css/default.css" rel="stylesheet" />
  <link href="main_files/ioslides-13.5.1/theme/css/phone.css" rel="stylesheet" />
  <script src="main_files/ioslides-13.5.1/js/modernizr.custom.45394.js"></script>
  <script src="main_files/ioslides-13.5.1/js/prettify/prettify.js"></script>
  <script src="main_files/ioslides-13.5.1/js/prettify/lang-r.js"></script>
  <script src="main_files/ioslides-13.5.1/js/prettify/lang-yaml.js"></script>
  <script src="main_files/ioslides-13.5.1/js/hammer.js"></script>
  <script src="main_files/ioslides-13.5.1/js/slide-controller.js"></script>
  <script src="main_files/ioslides-13.5.1/js/slide-deck.js"></script>

  <style type="text/css">

    b, strong {
      font-weight: bold;
    }

    em {
      font-style: italic;
    }

    slides > slide {
      -webkit-transition: all 0.4s ease-in-out;
      -moz-transition: all 0.4s ease-in-out;
      -o-transition: all 0.4s ease-in-out;
      transition: all 0.4s ease-in-out;
    }

    .auto-fadein {
      -webkit-transition: opacity 0.6s ease-in;
      -webkit-transition-delay: 0.4s;
      -moz-transition: opacity 0.6s ease-in 0.4s;
      -o-transition: opacity 0.6s ease-in 0.4s;
      transition: opacity 0.6s ease-in 0.4s;
      opacity: 0;
    }

    slides > slide:not(.nobackground):before {
      font-size: 12pt;
      content: "";
      position: absolute;
      bottom: 20px;
      left: 60px;
      background: url(main_files/logo.jpg) no-repeat 0 50%;
      -webkit-background-size: 30px 30px;
      -moz-background-size: 30px 30px;
      -o-background-size: 30px 30px;
      background-size: 30px 30px;
      padding-left: 40px;
      height: 30px;
      line-height: 1.9;
    }
  </style>

  <link rel="stylesheet" href="assets\css\ioslides.css" type="text/css" />

</head>

<body style="opacity: 0">

<slides class="layout-widescreen">

  <slide class="title-slide segue nobackground">
        <aside class="gdbar"><img src="main_files/logo.jpg"></aside>
        <!-- The content of this hgroup is replaced programmatically through the slide_config.json. -->
    <hgroup class="auto-fadein">
      <h1 data-config-title><!-- populated from slide_config.json --></h1>
      <h2 data-config-subtitle><!-- populated from slide_config.json --></h2>
      <p data-config-presenter><!-- populated from slide_config.json --></p>
          </hgroup>
  </slide>

<slide class=''><hgroup><h2>Out-of-sample predictive performance</h2></hgroup><article  id="out-of-sample-predictive-performance">

<ul>
<li>A model&#39;s fit to new data can be summarized numerically by

<ul>
<li>the <em>MSE</em></li>
<li>the \(\log\) predictive density (log-likelihood)

<ul>
<li>it is proportional to the mean squared error if the model is normal with constant variance</li>
</ul></li>
</ul></li>
<li>The ideal measure of a model&#39;s fit is the <em>out-of-sample</em> predictive performance for new data produced from the true data-generating process \[
\log p_{post}(\tilde y_i) = \log \textrm E_{post}(p(\tilde y_i\vert\theta)) = \log \int p(\tilde y_i \vert\theta)p_{post}(\theta)d\theta
\]</li>
</ul>

</article></slide><slide class=''><hgroup><h2>Estimating out-of-sample pointwise predictive accuracy</h2></hgroup><article  id="estimating-out-of-sample-pointwise-predictive-accuracy">

<p>Let&#39;s \(y_1, \ldots ,y_n\) and consider the posterior predictive distribution \[
p(\tilde y\vert y) = \int p(\tilde y_i \vert\theta)p(\theta\vert y)d\theta
\]</p>

<ul>
<li>To get comparability with the given dataset and easier interpretation of the differences in scale of effective numbers of parameter, consider \[
\begin{align}
\textrm{elppd} &amp; = \textrm{expected log pointwise predictive density for a new dataset} \\
 &amp; = \sum_{i=1}^n E_{f_i}(\log p(\tilde y\vert y))
\end{align}
\] \(f_i\) being the distribution representing the true data-generating process</li>
</ul>

</article></slide><slide class=''><hgroup><h2>Log pointwise predictive density</h2></hgroup><article  id="log-pointwise-predictive-density">

<p>\[
\begin{align}
\textrm{lppd} &amp; = \textrm{log pointwise predictive density} \\
 &amp; = \sum_{i=1}^n \log p(\tilde y\vert y) = \sum_{i=1}^n \log \int p(y_i\vert\theta)p(\theta\vert y)d\theta
\end{align}
\] - To compute lppd in practice, expectation can be computed by drawing from \(p(\theta\vert y)\)</p>

<p>\[
\begin{align}
\hat{\textrm{lpd}} &amp; = \textrm{computed log pointwise predictive density} \\
  &amp; = \sum_{i=1}^n \log \left(\frac{1}{S} \sum_{s=1}^S p(y_i\vert\theta^s)\right)\\
\end{align}
\]</p>

</article></slide><slide class=''><hgroup><h2>Estimating out-of-sample accuracy</h2></hgroup><article  id="estimating-out-of-sample-accuracy">

<p>Several methods are available to estimate the expected predictive accuracy without waiting for out-of-sample data (by computing lppd)</p>

<ul>
<li><p><em>within-sample predictive accuracy:</em> naive estimate of the expected log predictive density for new data baed on the log predictive density for existing data</p></li>
<li><em>adjusted within-sample predictive accuracy:</em> lppd is a biased estimate of elppd

<ul>
<li>AIC, DIC, and WAIC give approximately unbiased estimates of elppd by subtracting to lppd a correction for the number of parameters being fit</li>
</ul></li>
<li><p><em>crossvalidation:</em> fitting the model to training data and then evaluating this predictive accuracy on a holdout set</p></li>
</ul>

</article></slide><slide class=''><hgroup><h2>AIC and DIC</h2></hgroup><article  id="aic-and-dic">

<p>\[
\hat{\textrm{elpd}}_{AIC} = \log p(y\vert\hat\theta_{MLE}) - k
\] \[
\hat{\textrm{elpd}}_{DIC} = \log p(y\vert\hat\theta_{Bayes}) - p_{DIC}
\]</p>

<p>where \(\hat\theta_{Bayes}\) is the posterior mean \((\hat\theta_{Bayes} = \textrm E(\theta\vert y))\)</p>

<ul>
<li>\(p_{DIC}\) is the effective number of parameters defined as \[
p_{DIC} = 2\left(\log p(y\vert\hat\theta_{Bayes}) - \textrm E(\log p(y\vert\theta))\right)
\]</li>
</ul>

</article></slide><slide class=''><hgroup><h2>WAIC (Watanabe_Akaike IC or widely applicable IC)</h2></hgroup><article  id="waic-watanabe_akaike-ic-or-widely-applicable-ic">

<ul>
<li><p>WAIC is a more fully approach for estimating the out-of-sample expectation</p></li>
<li><p>It is based on \[
\hat{\textrm{elppd}}_{WAIC} = \hat{\textrm{lppd}} - \hat{p}_{WAIC}
\] that is \[
\sum_{i=1}^n \left(\log \left(\frac{1}{S} \sum_{s=1}^S p(y_i\vert\theta^s)\right)- \frac{1}{S} \sum_{s=1}^S \log p(y_i\vert\theta^s)\right)
\]</p></li>
</ul>

</article></slide><slide class=''><hgroup><h2>WAIC</h2></hgroup><article  id="waic">

<ul>
<li>If one wishes to use the deviance scale so as to be comparable to AIC and DIC:</li>
</ul>

<p>\[
\textrm{WAIC} = - 2 \hat{\textrm{elppd}}_{\textrm{waic}}
\]</p>

<ul>
<li>It can be interpreted as a computationally convenient approximation to cross-validation</li>
</ul>

</article></slide><slide class=''><hgroup><h2>AIC, DIC, WAIC</h2></hgroup><article  id="aic-dic-waic">

<ul>
<li>Compared to AIC and DIC, WAIC has the property of averaging over the posterior distribution rather than conditioning on a point estimate</li>
</ul>

</article></slide><slide class=''><hgroup><h2>Leave-one-out (Loo) crossvalidation</h2></hgroup><article  id="leave-one-out-loo-crossvalidation">

<ul>
<li>In Bayesian cross-validation, the data are repeatedly partitioned into a training set \(y_{train}\) and a holdout set \(y_{holdout}\), and then the model is fit to \(y_{train}\)

<ul>
<li>getting a posterior distribution \(p(\theta\vert y_{train})\)</li>
</ul></li>
<li>This fit is evaluated using an estimate of the log predictive density of the holdout data</li>
</ul>

<p>\[
\log p(y_{holdout}\vert y_{train}) = \log \int p(y_{holdout}\vert\theta)p(\theta\vert y_{train})
\] - Assuming the posterior distribution \(p(\theta\vert y_{train})\) is summarized by \(S\) simulation draws \(\theta^s\), log predictive density is \[
\log \left(\frac{1}{S} \sum_{s=1}^S p(y_{holdout}\vert\theta^s)\right)
\]</p>

</article></slide><slide class=''><hgroup><h2>Leave-one-out (Loo) crossvalidation</h2></hgroup><article  id="leave-one-out-loo-crossvalidation-1">

<ul>
<li>Performing the analysis for each of the \(n\) data points yields \(n\) different inferences \(p_{\textrm{post}(-i)}\)</li>
<li><p>Each of them is summarized by \(S\) posterior simulations \(\theta^{is}\)</p></li>
<li><p>The Bayesian LOO-CV estimate of out-of-sample predictive fit is \[
\textrm{lppd}_{loo} = \sum_{i=1}^n \log p_{\textrm{post}(-i)}(y_i)
\] computed as</p></li>
</ul>

<p>\[
\sum_{i=1}^n \log \left(\frac{1}{S} \sum_{s=1}^S p(y_i\vert\theta^{is})\right)
\] ## DIC: computational note {.smaller}</p>

<p>For a hierarchical model with the structure \[
\begin{array}{rl}
Y_i \vert u_i &amp;\sim&amp; f(y_i\vert u_i, \boldsymbol\theta)\\
u_i &amp;\sim&amp; f(u_i\vert \boldsymbol\theta_u)\\
\end{array}
\] DIC is computed using deviance measure \[
D_c(\mathbf u, \boldsymbol \theta) = -2\log f(\mathbf y\vert \mathbf u, \boldsymbol \theta)
\] based on the conditional likelihood \[
f(\mathbf y\vert \mathbf u, \boldsymbol \theta) = \prod_{i=1}^n
 f(y_i\vert u_i,\boldsymbol \theta)
\]</p>

<p>DIC is given by \[
\text{DIC} = 2\overline{D_c(\mathbf u, \boldsymbol \theta)}-D_c(\bar{\mathbf u}, \bar{\boldsymbol \theta})
\]</p>

</article></slide><slide class=''><hgroup><h2>DIC: computational note</h2></hgroup><article  id="dic-computational-note">

<p>When model is fitted directly \[
Y_i \sim f(y_i\vert \boldsymbol \theta, \boldsymbol \theta_u)
\] based on the marginal distribution \[
f(Y_i\vert \boldsymbol \theta, \boldsymbol \theta_u) = \int f(Y_i\vert\boldsymbol \theta, u_i) f(u_i\vert\boldsymbol \theta_u)du_i
\] the DIC is given by \[
\text{DIC} = 2\overline{D(\boldsymbol \theta, \boldsymbol \theta_u)}-D(\bar{\boldsymbol\theta}, \bar{\boldsymbol \theta}_u)
\] with \[
D(\boldsymbol\theta, \boldsymbol \theta_u) = -2\sum_{i=1}^n \log f(Y_i\vert\boldsymbol\theta, \boldsymbol \theta_u)
\]</p>

</article></slide><slide class=''><hgroup><h2>LOO in STAN</h2></hgroup><article  id="loo-in-stan" class="smaller">

<pre class = 'prettyprint lang-r'>&#39;data {
int P;                           // Number of regression predictors
int N_t;                         // (Training) number of data points
int&lt;lower=0,upper=1&gt; y_t[N_t];   // (Training) binary data
matrix[N_t,P] X_t;               // (Training) predictors
int N_h;                         // (Holdout)
int y_h[N_h];                    // (Holdout)
matrix[N_h,P] X_h;               // (Holdout)
real a;
}
parameters {
vector[P] b;
}
model {
y_t ~ bernoulli_logit(X_t*b);
}
generated quantities {
vector[N_t] log_lik_t;
vector[N_h] log_lik_h;
for (n in 1:N_t)
log_lik_t[n] = bernoulli_logit_lpmf(y_t[n] | X_t[n]*b);
for (n in 1:N_h)
log_lik_h[n] = bernoulli_logit_lpmf(y_h[n] | X_h[n]*b);
}&#39;</pre>

<pre >## [1] &quot;data {\nint P;                           // Number of regression predictors\nint N_t;                         // (Training) number of data points\nint&lt;lower=0,upper=1&gt; y_t[N_t];   // (Training) binary data\nmatrix[N_t,P] X_t;               // (Training) predictors\nint N_h;                         // (Holdout)\nint y_h[N_h];                    // (Holdout)\nmatrix[N_h,P] X_h;               // (Holdout)\nreal a;\n}\nparameters {\nvector[P] b;\n}\nmodel {\ny_t ~ bernoulli_logit(X_t*b);\n}\ngenerated quantities {\nvector[N_t] log_lik_t;\nvector[N_h] log_lik_h;\nfor (n in 1:N_t)\nlog_lik_t[n] = bernoulli_logit_lpmf(y_t[n] | X_t[n]*b);\nfor (n in 1:N_h)\nlog_lik_h[n] = bernoulli_logit_lpmf(y_h[n] | X_h[n]*b);\n}&quot;</pre>

</article></slide><slide class=''><hgroup><h2>loo package in R</h2></hgroup><article  id="loo-package-in-r">

<ul>
<li>loo package contrain the function <em>extract_log_lik</em></li>
</ul>

<pre class = 'prettyprint lang-r'>&#39;generated quantities {
vector[N] log_lik;
for (n in 1:N) log_lik[n] = normal_lpdf(y[n] | X[n] * beta, sigma)
}&#39;</pre>

<pre >## [1] &quot;generated quantities {\nvector[N] log_lik;\nfor (n in 1:N) log_lik[n] = normal_lpdf(y[n] | X[n] * beta, sigma)\n}&quot;</pre>

<pre class = 'prettyprint lang-r'>log_lik &lt;- extract_log_lik(stanfit1) 
loo(log_lik1)</pre>

</article></slide><slide class='segue dark nobackground level1'><hgroup class = 'auto-fadein'><h2>Just Another Example</h2></hgroup><article  id="just-another-example">

</article></slide><slide class=''><hgroup><h2>A simple crossover trial</h2></hgroup><article  id="a-simple-crossover-trial">

<ul>
<li><strong>Crossover trial:</strong> different treatments are given with different sequences in groups of patients</li>
</ul>

<center>

<img src="images/Crossover.png" width="800px" height="400px"/>

</center>

</article></slide><slide class=''><hgroup><h2>Brown&amp;Prescott (Applied Mixed Models in Medicine, 2006)</h2></hgroup><article  id="brownprescott-applied-mixed-models-in-medicine-2006" class="smaller">

<ul>
<li>Comparison of two diuretics in the treatment of mild and moderate heart failure</li>
<li>Baseline observation were taken before the first treatment period</li>
<li>The duration of each treatment period was 5 days without any washout period

<ul>
<li>to avoid carryover effects, measurement of the first 2 days were ignored</li>
</ul></li>
<li>Two endpoint analyzed:

<ul>
<li>edema status (OED)

<ul>
<li>the sum of left and right ankle diameters</li>
</ul></li>
<li>diastolic blood preassure (DBP)

<ul>
<li>the sum of 3 DBP readings</li>
</ul></li>
</ul></li>
<li><strong>Aim: compare the effectiveness of the two treatments</strong></li>
</ul>

</article></slide><slide class=''><hgroup><h2>Brown&amp;Prescott (Applied Mixed Models in Medicine, 2006)</h2></hgroup><article  id="brownprescott-applied-mixed-models-in-medicine-2006-1">

<table class = 'rmdtable'>
<tr class="header">
<th align="right">X</th>
<th align="right">patient</th>
<th align="right">treatment</th>
<th align="left">period</th>
<th align="right">oedbase</th>
<th align="right">dbpbase</th>
<th align="right">oed</th>
<th align="right">dbp</th>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="left">1</td>
<td align="right">45</td>
<td align="right">60.00000</td>
<td align="right">45</td>
<td align="right">55.00000</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="left">2</td>
<td align="right">45</td>
<td align="right">60.00000</td>
<td align="right">45</td>
<td align="right">60.00000</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">2</td>
<td align="right">1</td>
<td align="left">1</td>
<td align="right">51</td>
<td align="right">50.00000</td>
<td align="right">48</td>
<td align="right">60.00000</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">2</td>
<td align="right">2</td>
<td align="left">2</td>
<td align="right">51</td>
<td align="right">50.00000</td>
<td align="right">48</td>
<td align="right">65.00000</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">3</td>
<td align="right">1</td>
<td align="left">1</td>
<td align="right">53</td>
<td align="right">70.00000</td>
<td align="right">50</td>
<td align="right">70.00000</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">3</td>
<td align="right">2</td>
<td align="left">2</td>
<td align="right">53</td>
<td align="right">70.00000</td>
<td align="right">52</td>
<td align="right">80.00000</td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="right">4</td>
<td align="right">2</td>
<td align="left">1</td>
<td align="right">49</td>
<td align="right">68.33333</td>
<td align="right">47</td>
<td align="right">60.00000</td>
</tr>
<tr class="even">
<td align="right">8</td>
<td align="right">4</td>
<td align="right">1</td>
<td align="left">2</td>
<td align="right">49</td>
<td align="right">68.33333</td>
<td align="right">47</td>
<td align="right">60.00000</td>
</tr>
<tr class="odd">
<td align="right">9</td>
<td align="right">5</td>
<td align="right">1</td>
<td align="left">1</td>
<td align="right">46</td>
<td align="right">65.00000</td>
<td align="right">45</td>
<td align="right">60.00000</td>
</tr>
<tr class="even">
<td align="right">10</td>
<td align="right">5</td>
<td align="right">2</td>
<td align="left">2</td>
<td align="right">46</td>
<td align="right">65.00000</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="odd">
<td align="right">11</td>
<td align="right">6</td>
<td align="right">1</td>
<td align="left">1</td>
<td align="right">61</td>
<td align="right">95.33333</td>
<td align="right">60</td>
<td align="right">94.66667</td>
</tr>
</table>

</article></slide><slide class=''><hgroup><h2>Brown&amp;Prescott (Applied Mixed Models in Medicine, 2006)</h2></hgroup><article  id="brownprescott-applied-mixed-models-in-medicine-2006-2">

<p>Four models were fitted for each response (OED and DBP) and compared using DIC and WAIC:</p>

<ul>
<li>treatment and period effect were included in the analysis as fixed effects</li>
<li>patient effect was included as either fixed or random effect</li>
<li>baseline measures were introduced in two models to assess their importance</li>
<li>an additional model with interaction effect between the period and the treatment to account for possible <em>carryover</em> effects</li>
</ul>

</article></slide><slide class=''><hgroup><h2>Models formulation</h2></hgroup><article  id="models-formulation">

<p>\[
\begin{align}
Y_i &amp; \sim  \textrm N(\mu_i, \sigma^2)\\
\mu_i &amp; =  \beta_1 + \beta_2\textrm{period}_i + \beta_3 T_i + \gamma_1 a^{\textrm{random}}_{P_i} + (1-\gamma_1) a^{\textrm{fixed}}_{P_i} + \gamma_2 \beta_4 B_i \\
a^{\textrm{random}}_{k} &amp; \sim  \textrm N(0,\sigma^2_{\textrm{patients}})\\
a^{\textrm{fixed}}_{k} &amp; \sim  \textrm N(0,10^{-3})\\
\end{align}
\]</p>

</article></slide><slide class=''><hgroup><h2>Model 1: fixed effects + no baseline</h2></hgroup><article  id="model-1-fixed-effects-no-baseline" class="smaller">

<pre class = 'prettyprint lang-r'>library(rstan)
library(glmer2stan)
source(&#39;R\\myglmer2stan.R&#39;)
mod_1 &lt;- myglmer2stan(oed ~ period + treatment + patient,
                      data = crossover, 
                      calcWAIC = T, calcDIC = T,
                      Ranef = F)</pre>

</article></slide><slide class=''><hgroup><h2>Model 2: random effects + no baseline</h2></hgroup><article  id="model-2-random-effects-no-baseline" class="smaller">

<pre class = 'prettyprint lang-r'>library(rstan)
library(glmer2stan)
source(&#39;R\\myglmer2stan.R&#39;)
mod_2 &lt;- myglmer2stan(oed ~ period + treatment + (1|patient),
                      data = crossover, 
                      calcWAIC = T, calcDIC = T,
                      Ranef = T)</pre>

</article></slide><slide class=''><hgroup><h2>Model 3: fixed effects + baseline</h2></hgroup><article  id="model-3-fixed-effects-baseline" class="smaller">

<pre class = 'prettyprint lang-r'>library(rstan)
library(glmer2stan)
source(&#39;R\\myglmer2stan.R&#39;)
mod_3 &lt;- myglmer2stan(oed ~ period + treatment + oedbase + patient,
                      data = crossover, 
                      calcWAIC = T, calcDIC = T,
                      Ranef = F)</pre>

</article></slide><slide class=''><hgroup><h2>Model 4: random effects + baseline</h2></hgroup><article  id="model-4-random-effects-baseline" class="smaller">

<pre class = 'prettyprint lang-r'>library(rstan)
library(glmer2stan)
source(&#39;R\\myglmer2stan.R&#39;)
mod_4 &lt;- myglmer2stan(oed ~ period + treatment + oedbase + (1|patient),
                      data = crossover, 
                      calcWAIC = T, calcDIC = T,
                      Ranef = T)</pre>

</article></slide><slide class=''><hgroup><h2>Extract within-patient and between-patient variance</h2></hgroup><article  id="extract-within-patient-and-between-patient-variance">

<pre class = 'prettyprint lang-r'>library(rstan)</pre>

<pre >## Loading required package: ggplot2</pre>

<pre >## Loading required package: StanHeaders</pre>

<pre >## rstan (Version 2.15.1, packaged: 2017-04-19 05:03:57 UTC, GitRev: 2e1f913d3ca3)</pre>

<pre >## For execution on a local, multicore CPU with excess RAM we recommend calling
## rstan_options(auto_write = TRUE)
## options(mc.cores = parallel::detectCores())</pre>

<pre class = 'prettyprint lang-r'>s_pat &lt;- unlist(extract(mod_4,&#39;sigma_patient&#39;))
s &lt;- unlist(extract(mod_4,&#39;sigma&#39;))</pre>

</article></slide><slide class=''><hgroup><h2>Compute the correlation within-patient (ICC)</h2></hgroup><article  id="compute-the-correlation-within-patient-icc">

<pre class = 'prettyprint lang-r'>cor &lt;- s_pat^2/(s^2+s_pat^2)
quantile(cor, probs = c(0.025, 0.5, .975))</pre>

<pre >##      2.5%       50%     97.5% 
## 0.8149044 0.8766828 0.9190104</pre>

</article></slide><slide class=''><hgroup><h2>Choose the model</h2></hgroup><article  id="choose-the-model">

</article></slide><slide class=''><hgroup><h2>Predictive accuracy</h2></hgroup><article  id="predictive-accuracy">

<ul>
<li><p>After fitting a Bayesian model, how to measure its predictive accuracy?</p></li>
<li><em>WAIC</em> (the Watanabe-Akaike or widely applicable information criterion) is an improvement on the deviance information criterion (<em>DIC</em>)

<ul>
<li>DIC is based on a point estimate (no fully Bayesian)</li>
<li>DIC can produce negative estimates of the effective number of parameters in a model</li>
</ul></li>
<li>WAIC is fully Bayesian and closely approximates Bayesian cross-validation

<ul>
<li>Unlike DIC, WAIC is invariant to parametrization</li>
</ul></li>
</ul>

</article></slide><slide class=''><hgroup><h2>WAIC to choose models</h2></hgroup><article  id="waic-to-choose-models">

<ul>
<li>WAIC and DIC</li>
</ul>

<table class = 'rmdtable'>
<tr class="header">
<th align="left">Model</th>
<th align="right">WAIC</th>
<th align="right">pWAIC</th>
<th align="right">DIC</th>
<th align="right">pDIC</th>
<th align="right">lppd</th>
<th align="right">dev</th>
</tr>
<tr class="odd">
<td align="left">Model 1</td>
<td align="right">461.58</td>
<td align="right">66.54</td>
<td align="right">470.59</td>
<td align="right">96.56</td>
<td align="right">-164.20</td>
<td align="right">277.47</td>
</tr>
<tr class="even">
<td align="left">Model 2</td>
<td align="right">461.62</td>
<td align="right">66.88</td>
<td align="right">469.87</td>
<td align="right">96.12</td>
<td align="right">-163.93</td>
<td align="right">277.63</td>
</tr>
<tr class="odd">
<td align="left">Model 3</td>
<td align="right">460.75</td>
<td align="right">66.72</td>
<td align="right">469.14</td>
<td align="right">96.09</td>
<td align="right">-360.63</td>
<td align="right">723.92</td>
</tr>
<tr class="even">
<td align="left">Model 4</td>
<td align="right">456.00</td>
<td align="right">63.90</td>
<td align="right">461.00</td>
<td align="right">88.70</td>
<td align="right">-163.95</td>
<td align="right">283.60</td>
</tr>
</table>

<ul>
<li>To check for deviations from the normality assumption, the log-normal distribution can be used (higher DIC values)</li>
</ul>

</article></slide><slide class=''><hgroup><h2>Log-normal distribution</h2></hgroup><article  id="log-normal-distribution">

<pre class = 'prettyprint lang-r'>&#39;generated quantities{
    real dev;
    real vary[N];
    real glm[N];
vector[N] log_lik;
    dev &lt;- 0;
    for ( i in 1:N ) {
        vary[i] &lt;- vary_patient[patient[i]];
        glm[i] &lt;- vary[i] + Intercept
                + beta_period2 * period2[i]
                + beta_treatment * treatment[i]
                + beta_oedbase * oedbase[i];
log_lik[i] = normal_lpdf(oed[i] | glm[i], sigma);
        dev &lt;- dev + (-2) * normal_log( oed[i] , glm[i] , sigma );
    }
}
&#39;</pre>

<pre >## [1] &quot;generated quantities{\n    real dev;\n    real vary[N];\n    real glm[N];\nvector[N] log_lik;\n    dev &lt;- 0;\n    for ( i in 1:N ) {\n        vary[i] &lt;- vary_patient[patient[i]];\n        glm[i] &lt;- vary[i] + Intercept\n                + beta_period2 * period2[i]\n                + beta_treatment * treatment[i]\n                + beta_oedbase * oedbase[i];\nlog_lik[i] = normal_lpdf(oed[i] | glm[i], sigma);\n        dev &lt;- dev + (-2) * normal_log( oed[i] , glm[i] , sigma );\n    }\n}\n&quot;</pre>

</article></slide><slide class=''><hgroup><h2>Final Model</h2></hgroup><article  id="final-model">

<pre class = 'prettyprint lang-r'>stanmer(mod_4)</pre>

<pre >## glmer2stan model: oed ~ period + treatment + oedbase + (1 | patient) [gaussian]
## 
## Level 1 estimates:
##             Expectation StdDev  2.5% 97.5%
## (Intercept)        0.04   1.53 -3.05  2.99
## period2           -0.24   0.12 -0.48  0.00
## treatment         -0.31   0.12 -0.55 -0.08
## oedbase            0.99   0.03  0.94  1.04
## sigma              0.74   0.06  0.63  0.87
## 
## Level 2 estimates:
## (Std.dev. and correlations)
## 
## Group: patient (94 groups / imbalance: 0)
##   (Intercept)  1.97  (SE 0.16)
## 
## DIC: 461   pDIC: 88.7   Deviance: 283.6
## 
## WAIC: 456   pWAIC: 63.9   -2*lppd: 327.9</pre>

</article></slide><slide class=''><hgroup><h2>Give a try to rstanarm</h2></hgroup><article  id="give-a-try-to-rstanarm">

<pre class = 'prettyprint lang-r'>library(rstanarm)

post2 &lt;- stan_lmer(oed ~ period + treatment + oedbase+ (1|patient), data=data)</pre>

</article></slide><slide class=''><hgroup><h2>Stan</h2></hgroup><article  id="stan">

<pre class = 'prettyprint lang-r'>pp_check(post1)</pre>

<center>

<img src="images/pp_check.png" width="600px" height="400px" />

</center>

</article></slide><slide class=''><hgroup><h2>Stan</h2></hgroup><article  id="stan-1">

<pre class = 'prettyprint lang-r'>library(ggplot2)

base &lt;- ggplot(data, aes(x = treatment, y = oed)) +
  geom_point(size=1, position=position_jitter(height = 0.05, width = 0.1)) +
  scale_x_continuous(breaks = c(1,2), labels = c(&#39;A&#39;, &#39;B&#39;)) 

draws &lt;- as.data.frame(post2)[,1:3]
draws &lt;- na.omit(draws)
colnames(draws)[1] =&#39;intercept&#39;
base + 
  geom_abline(data = draws, aes(intercept = intercept +mean(data$oedbase), slope = treatment),
              color = &#39;skyblue&#39;, size = 0.2, alpha = 0.25) +
  geom_abline(intercept = fixef(post2)[1] + mean(data$oedbase), slope = fixef(post2)[3],
              color = &#39;skyblue4&#39;, size = 1)</pre>

</article></slide><slide class=''><hgroup><h2>Stan</h2></hgroup><article  id="stan-2">

<center>

<img src="images/stan1.png" width="600px" height="400px" />

</center>

</article></slide><slide class=''><hgroup><h2>Stan: relationship with baseline</h2></hgroup><article  id="stan-relationship-with-baseline">

<pre class = 'prettyprint lang-r'>draws &lt;- as.data.frame(as.matrix(post2))
colnames(draws)[1] &lt;- &quot;intercept&quot;
ggplot(data, aes(x = oedbase, y = oed)) + 
  geom_point(size = 1) +
  geom_abline(data = draws, aes(intercept = intercept, slope = oedbase), 
              color = &quot;skyblue&quot;, size = 0.2, alpha = 0.25) + 
  geom_abline(intercept = fixef(post2)[1], slope = fixef(post2)[4], 
              color = &quot;skyblue4&quot;, size = 1)</pre>

</article></slide><slide class=''><hgroup><h2>Stan: relationship with baseline</h2></hgroup><article  id="stan-relationship-with-baseline-1">

<center>

<img src="images/stan2.png" width="600px" height="400px" />

</center>

</article></slide><slide class=''><hgroup><h2>The carry-over effect?</h2></hgroup><article  id="the-carry-over-effect">

<ul>
<li><p>Try to add an interaction term between the period and the treatment</p></li>
<li><p>It is worth modeling the carry-over effect?</p></li>
</ul>

</article></slide><slide class=''><hgroup><h2>Getting the slides</h2></hgroup><article  id="getting-the-slides">

<ul>
<li>The slides for this course were created with Rmarkdown: <a href='http://rmarkdown.rstudio.com/' title=''>http://rmarkdown.rstudio.com/</a>.</li>
<li>They are available from <a href='https://github.com/berkeley3/BDA-IZSTO' title=''>https://github.com/berkeley3/BDA-IZSTO</a>.</li>
<li><p>To re-compile the slides:</p>

<ul>
<li>Download the directory containing the lectures from Github</li>
<li>In R open the .Rmd file and set the working directory to the lecture directory</li>
<li>Click the <em>KnitHTML</em> button on Rstudio or run the following commands:</li>
</ul></li>
</ul>

<pre class = 'prettyprint lang-r'>library(rmarkdown) 
render(&quot;main.Rmd&quot;)</pre></article></slide>


  <slide class="backdrop"></slide>

</slides>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "main_files/mathjax-local/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!-- map slide visiblity events into shiny -->
<script>
  (function() {
    if (window.jQuery) {
       window.jQuery(document).on('slideleave', function(e) {
         window.jQuery(e.target).trigger('hidden');
      });
       window.jQuery(document).on('slideenter', function(e) {
         window.jQuery(e.target).trigger('shown');
      });
    }
  })();
</script>

</body>
</html>
